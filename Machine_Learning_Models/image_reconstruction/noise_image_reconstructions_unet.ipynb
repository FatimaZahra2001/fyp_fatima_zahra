{"cells":[{"cell_type":"markdown","id":"8ac9zAOO5oeW","metadata":{"id":"8ac9zAOO5oeW"},"source":["Mount google drive for google colab"]},{"cell_type":"code","execution_count":null,"id":"zR8T3r1W3PTp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17613,"status":"ok","timestamp":1712314126320,"user":{"displayName":"Fatima Zahra","userId":"01002387081529872312"},"user_tz":-60},"id":"zR8T3r1W3PTp","outputId":"4b28d91a-1b88-44ea-80ce-6ef174a5437f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Input folder '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/4_noise_img' found.\n","Output folder '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/16_noise_img' found.\n"]}],"source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","input_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/4_noise_img'\n","output_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/16_noise_img'\n","\n","if not os.path.exists(input_folder):\n","    print(f\"Input folder '{input_folder}' not found.\")\n","else:\n","    print(f\"Input folder '{input_folder}' found.\")\n","\n","if not os.path.exists(output_folder):\n","    print(f\"Output folder '{output_folder}' not found.\")\n","else:\n","    print(f\"Output folder '{output_folder}' found.\")\n"]},{"cell_type":"markdown","id":"UxmUzLKb5itE","metadata":{"id":"UxmUzLKb5itE"},"source":["U-Net model for perfect data."]},{"cell_type":"code","execution_count":null,"id":"K92zaAIZhcSt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":648955,"status":"ok","timestamp":1712328316935,"user":{"displayName":"Fatima Zahra","userId":"01002387081529872312"},"user_tz":-60},"id":"K92zaAIZhcSt","outputId":"9b0ad71a-b328-41e8-979e-2bd374ee99dc"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# function to load and preprocess images\n","def load_and_preprocess_images(folder_path):\n","    images = []\n","    for filename in os.listdir(folder_path):\n","        img_path = os.path.join(folder_path, filename)\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        if img is not None:\n","            img = cv2.resize(img, (128, 128))  # Resize images to (128, 128)\n","            img = img.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n","            images.append(img)\n","    return np.array(images)\n","\n","# folders for low resolution (4 sources and detectors) and high resolution (16 sources and detectors) images\n","low_res_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/4_noise_img'\n","high_res_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/16_noise_img'\n","\n","# Load and preprocess low resolution images\n","low_res_images = load_and_preprocess_images(low_res_folder)\n","\n","# Load and preprocess high resolution images\n","high_res_images = load_and_preprocess_images(high_res_folder)\n","\n","# split data into training and testing sets\n","train_low_images, test_low_images, train_high_images, test_high_images = train_test_split(\n","    low_res_images, high_res_images, test_size=0.2, random_state=42\n",")\n","\n","# U-Net model architecture\n","def unet(input_shape):\n","    inputs = tf.keras.Input(shape=input_shape)\n","\n","    # Encoder\n","    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n","    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n","    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n","    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n","    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n","    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n","    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n","    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n","    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    # Bottleneck\n","    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n","    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n","\n","    # Decoder\n","    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv5)\n","    up6 = layers.concatenate([up6, conv4], axis=3)\n","    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(up6)\n","    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n","\n","    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n","    up7 = layers.concatenate([up7, conv3], axis=3)\n","    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(up7)\n","    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n","\n","    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n","    up8 = layers.concatenate([up8, conv2], axis=3)\n","    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(up8)\n","    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n","\n","    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n","    up9 = layers.concatenate([up9, conv1], axis=3)\n","    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(up9)\n","    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n","\n","    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv9) \n","\n","    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"img_to_img_unet\")\n","    return model\n","\n","\n","# build U-Net model\n","input_shape = (128, 128, 1)  # Adjust input shape based on your data\n","model = unet(input_shape)\n","\n","# define the optimiser with a custom learning rate\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","\n","model.compile(optimizer=optimizer, loss='mean_squared_error')\n","\n","# define a ModelCheckpoint callback to save the model during training\n","checkpoint_path = 'trained_unet_img_to_img_model.h5'\n","model_checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True)\n","\n","model.fit(train_low_images, train_high_images,\n","          epochs=200, batch_size=32, validation_split=0.2, callbacks=[model_checkpoint])\n","\n","\n","# fefine a ModelCheckpoint callback to save the model during training\n","checkpoint_path = 'trained_unet_img_to_img_model.h5'\n","model_checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True)\n","\n","model.evaluate(test_low_images, test_high_images)\n","\n","model.save('trained_unet_img_to_img_model.h5')\n"]},{"cell_type":"markdown","id":"10MO_Yuv5zdp","metadata":{"id":"10MO_Yuv5zdp"},"source":["U-Net for Noise data."]},{"cell_type":"code","execution_count":null,"id":"3bdQNae_3MUN","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3173805,"status":"ok","timestamp":1712324684525,"user":{"displayName":"Fatima Zahra","userId":"01002387081529872312"},"user_tz":-60},"id":"3bdQNae_3MUN","outputId":"8bec8d45-c012-4b0a-97d9-62d09eb33ac3"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# define function to load and preprocess images\n","def load_and_preprocess_images(folder_path):\n","    images = []\n","    for filename in os.listdir(folder_path):\n","        img_path = os.path.join(folder_path, filename)\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        if img is not None:\n","            img = cv2.resize(img, (128, 128))  # resize images to (128, 128)\n","            img = img.astype('float32') / 255.0  # normalize pixel values to [0, 1]\n","            images.append(img)\n","    return np.array(images)\n","\n","# define U-Net model\n","def img_unet(input_shape, num_filters, kernel_size, optimizer, learning_rate):\n","    inputs = tf.keras.Input(shape=input_shape)\n","\n","    # encoder\n","    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n","    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n","    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n","    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n","    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n","    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n","    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n","    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n","    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n","    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n","    pool5 = layers.MaxPooling2D(pool_size=(2, 2))(conv5)\n","\n","    # bottleneck\n","    conv6 = layers.Conv2D(2048, 3, activation='relu', padding='same')(pool5)\n","    conv6 = layers.Conv2D(2048, 3, activation='relu', padding='same')(conv6)\n","\n","    # decoder\n","    up7 = layers.Conv2DTranspose(1024, 2, strides=(2, 2), padding='same')(conv6)\n","    up7 = layers.concatenate([up7, conv5], axis=3)\n","    conv7 = layers.Conv2D(1024, 3, activation='relu', padding='same')(up7)\n","    conv7 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv7)\n","\n","    up8 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(conv7)\n","    up8 = layers.concatenate([up8, conv4], axis=3)\n","    conv8 = layers.Conv2D(512, 3, activation='relu', padding='same')(up8)\n","    conv8 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv8)\n","\n","    up9 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv8)\n","    up9 = layers.concatenate([up9, conv3], axis=3)\n","    conv9 = layers.Conv2D(256, 3, activation='relu', padding='same')(up9)\n","    conv9 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv9)\n","\n","    up10 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv9)\n","    up10 = layers.concatenate([up10, conv2], axis=3)\n","    conv10 = layers.Conv2D(128, 3, activation='relu', padding='same')(up10)\n","    conv10 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv10)\n","\n","    up11 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv10)\n","    up11 = layers.concatenate([up11, conv1], axis=3)\n","    conv11 = layers.Conv2D(64, 3, activation='relu', padding='same')(up11)\n","    conv11 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv11)\n","\n","    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv11)\n","\n","    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"img_unet_complex\")\n","    return model\n","\n","low_res_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/4_noise_img'\n","high_res_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/16_noise_img'\n","\n","# load and preprocess low resolution images\n","low_res_images = load_and_preprocess_images(low_res_folder)\n","\n","# load and preprocess high resolution images\n","high_res_images = load_and_preprocess_images(high_res_folder)\n","\n","# split data into training and testing sets\n","train_low_images, test_low_images, train_high_images, test_high_images = train_test_split(\n","    low_res_images, high_res_images, test_size=0.2, random_state=42\n",")\n","\n","learning_rate = 0.001\n","num_filters = 64\n","kernel_size = 5\n","optimizer = 'adam'\n","input_shape = (128, 128, 1)\n","model = img_unet(input_shape=input_shape, num_filters=num_filters, kernel_size=kernel_size,\n","                 optimizer=optimizer, learning_rate=learning_rate)\n","\n","# compile the model\n","model.compile(optimizer=optimizer, loss='mean_squared_error')\n","\n","# define a ModelCheckpoint callback to save the model during training\n","checkpoint_path = 'trained_unet_img_to_img_model.h5'\n","model_checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True)\n","\n","# train the model\n","model.fit(train_low_images, train_high_images,\n","          epochs=150, batch_size=32, validation_split=0.2, callbacks=[model_checkpoint])\n","\n","model.evaluate(test_low_images, test_high_images)\n","\n","model.save('trained_unet_img_to_img_model.h5')\n"]},{"cell_type":"markdown","id":"CL9MB9azEKgu","metadata":{"id":"CL9MB9azEKgu"},"source":["Testing my model on new data."]},{"cell_type":"code","execution_count":null,"id":"7e55211b-4a3f-4753-9ad2-fe1e9a47f62e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3838,"status":"ok","timestamp":1712328613121,"user":{"displayName":"Fatima Zahra","userId":"01002387081529872312"},"user_tz":-60},"id":"7e55211b-4a3f-4753-9ad2-fe1e9a47f62e","outputId":"e6c186a8-c291-4339-a08d-1cac07c9de7a"},"outputs":[],"source":["import os\n","import random\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import load_model\n","\n","# load the trained model\n","model = load_model(\"trained_unet_img_to_img_model.h5\")\n","\n","# define function to load and preprocess a single image\n","def load_and_preprocess_image(image_path):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    if image is not None:\n","        image = cv2.resize(image, (128, 128))  # Resize image to (128, 128)\n","        image = image.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n","    return image  \n","\n","input_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/4_noise_img'\n","output_folder = '/content/drive/MyDrive/Colab Notebooks/fyp/images/noise_data/16_noise_img'\n","\n","image_filenames = os.listdir(input_folder)\n","\n","num_images_to_test = 8  \n","random_image_filenames = random.sample(image_filenames, num_images_to_test)\n","\n","# initialize list to store images\n","images = []\n","\n","for random_image_filename in random_image_filenames:\n","    input_image_path = os.path.join(input_folder, random_image_filename)\n","    input_image = load_and_preprocess_image(input_image_path)\n","\n","    # skip processing if image loading fails\n","    if input_image is None:\n","        print(f\"Skipping image: {random_image_filename} (failed to load)\")\n","        continue\n","\n","    # reshape input image for model prediction\n","    input_image = np.expand_dims(input_image, axis=0)\n","\n","    # predict the output image using the trained model\n","    output_image = model.predict(input_image)\n","\n","    # load the corresponding ground truth output image\n","    ground_truth_image_path = os.path.join(output_folder, random_image_filename)\n","    ground_truth_image = load_and_preprocess_image(ground_truth_image_path)\n","\n","    # skip processing if ground truth image loading fails\n","    if ground_truth_image is None:\n","        print(f\"Skipping image: {random_image_filename} (ground truth image failed to load)\")\n","        continue\n","\n","    plt.figure(figsize=(10, 5))\n","\n","    # original input image\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(input_image[0], cmap='gray')\n","    plt.title('Original Input Image')\n","    plt.axis('off')\n","\n","    # predicted output image\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(output_image[0, :, :, 0], cmap='gray')\n","    plt.title('Predicted Output Image')\n","    plt.axis('off')\n","\n","    # ground truth output image\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(ground_truth_image, cmap='gray')\n","    plt.title('Ground Truth Output Image')\n","    plt.axis('off')\n","\n","    plt.show()\n","\n","    images.append(np.concatenate([input_image[0], output_image[0, :, :, 0], ground_truth_image], axis=1))\n","\n","grid_image = np.concatenate(images, axis=0)\n","\n","cv2.imwrite(\"grid_image.png\", grid_image)\n","\n","plt.imshow(grid_image, cmap='gray')\n","plt.axis('off')\n","plt.show()\n"]},{"cell_type":"markdown","id":"PbFBEE1HEQIj","metadata":{"id":"PbFBEE1HEQIj"},"source":["Accuracy and loss graphs."]},{"cell_type":"code","execution_count":null,"id":"a11ddc7a-8f6e-4eee-9e6a-7e67e767adec","metadata":{"id":"a11ddc7a-8f6e-4eee-9e6a-7e67e767adec","outputId":"dab3cbc0-6761-428e-f53a-46804bb337a1"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage.metrics import structural_similarity as ssim\n","from skimage.metrics import peak_signal_noise_ratio as psnr\n","import os\n","import cv2\n","\n","def load_image_samples(input_folder, output_folder):\n","    image_samples = []\n","\n","    input_filenames = sorted(os.listdir(input_folder))\n","    output_filenames = sorted(os.listdir(output_folder))\n","\n","    for input_filename, output_filename in zip(input_filenames, output_filenames):\n","        input_img_path = os.path.join(input_folder, input_filename)\n","        output_img_path = os.path.join(output_folder, output_filename)\n","\n","        input_img = cv2.imread(input_img_path, cv2.IMREAD_GRAYSCALE)\n","        output_img = cv2.imread(output_img_path, cv2.IMREAD_GRAYSCALE)\n","\n","        if input_img is not None and output_img is not None:\n","            input_img = cv2.resize(input_img, (128, 128))  \n","            output_img = cv2.resize(output_img, (128, 128))  \n","\n","            input_img = input_img.astype('float32') / 255.0 \n","            output_img = output_img.astype('float32') / 255.0 \n","\n","            image_samples.append((input_img, output_img))\n","\n","    return image_samples\n","\n","input_folder = '/jupyter/work/fyp/data/img_rec/4th_set_noise/4_noise'\n","output_folder = '/jupyter/work/fyp/data/img_rec/4th_set_noise/16_noise'\n","image_samples = load_image_samples(input_folder, output_folder)\n","\n","\n","def load_ground_truth_images(folder_path):\n","    ground_truth_images = []\n","\n","    filenames = sorted(os.listdir(folder_path))\n","\n","    for filename in filenames:\n","        img_path = os.path.join(folder_path, filename)\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","\n","        if img is not None:\n","            img = cv2.resize(img, (128, 128)) \n","            img = img.astype('float32') / 255.0  \n","            ground_truth_images.append(img)\n","\n","    return ground_truth_images\n","\n","ground_truth_folder = '/jupyter/work/fyp/data/img_rec/4th_set_noise/16_noise'\n","reconstructions = '/jupyter/work/fyp/code/results/img'\n","ground_truth_images = load_ground_truth_images(ground_truth_folder)\n","\n","\n","# variables needed for analysis and plotting\n","train_losses = history.history['loss']\n","val_losses = history.history['val_loss']\n","train_accs = history.history['accuracy']  \n","val_accs = history.history['val_accuracy'] \n","reconstructed_images = load_ground_truth_images(reconstructions)\n","\n","# Loss Curves\n","def plot_loss_curves(train_losses, val_losses, task_name, save_dir):\n","    plt.plot(train_losses, label='Training Loss')\n","    plt.plot(val_losses, label='Validation Loss')\n","    plt.title(f'{task_name} Loss Curves')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig(os.path.join(save_dir, f'{task_name}_loss_curves.png'))\n","    plt.show()\n","\n","# # Accuracy Curves\n","def plot_accuracy_curves(train_accs, val_accs, task_name, save_dir):\n","    plt.plot(train_accs, label='Training Accuracy')\n","    plt.plot(val_accs, label='Validation Accuracy')\n","    plt.title(f'{task_name} Accuracy Curves')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.savefig(os.path.join(save_dir, f'{task_name}_accuracy_curves.png'))\n","    plt.show()\n","\n","results_folder = '/jupyter/work/fyp/code/results'\n","\n","# Now you can call the plotting and analysis functions with the defined variables\n","plot_loss_curves(train_losses, val_losses, 'Image Reconstruction', results_folder)\n","plot_accuracy_curves(train_accs, val_accs, 'Image Reconstruction', results_folder)\n","\n"]},{"cell_type":"markdown","id":"GTOmp71kEW2u","metadata":{"id":"GTOmp71kEW2u"},"source":["PSNR, SSIM, MSE variation graphs."]},{"cell_type":"code","execution_count":null,"id":"36ba9a00-e275-49c3-82e3-01be48263041","metadata":{"id":"36ba9a00-e275-49c3-82e3-01be48263041","outputId":"eaa587ca-8f50-476b-bf0c-d956dc1851b4"},"outputs":[],"source":["import os\n","import random\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage.metrics import peak_signal_noise_ratio, mean_squared_error, structural_similarity\n","from tensorflow.keras.models import load_model\n","\n","# PSNR loss function\n","def psnr_loss(y_true, y_pred):\n","    return -K.mean(10.0 * K.log(K.square(1.0) / (K.square(y_pred - y_true) + K.epsilon())) / K.log(10.0))\n","\n","model = load_model(\"unet_optimum_parameters.h5\", custom_objects={'psnr_loss': psnr_loss})\n","\n","# function to load and preprocess a single image\n","def load_and_preprocess_image(image_path):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    if image is not None:\n","        image = cv2.resize(image, (128, 128)) \n","        image = image.astype('float32') / 255.0 \n","    return image\n","\n","input_folder = '/jupyter/work/fyp/data/img_rec/3rd_set/4'\n","output_folder = '/jupyter/work/fyp/data/img_rec/3rd_set/16'\n","\n","image_filenames = os.listdir(input_folder)\n","\n","num_images_to_test = 10 \n","random_image_filenames = random.sample(image_filenames, num_images_to_test)\n","\n","psnr_scores = []\n","mse_scores = []\n","ssim_scores = []\n","\n","for random_image_filename in random_image_filenames:\n","    input_image_path = os.path.join(input_folder, random_image_filename)\n","    input_image = load_and_preprocess_image(input_image_path)\n","\n","    # reshape input image for model prediction\n","    input_image = np.expand_dims(input_image, axis=0)\n","\n","    # predict the output image using the trained model\n","    output_image = model.predict(input_image)\n","\n","    ground_truth_image_path = os.path.join(output_folder, random_image_filename)\n","    ground_truth_image = load_and_preprocess_image(ground_truth_image_path)\n","\n","    # calculate PSNR (Peak Signal-to-Noise Ratio)\n","    psnr_value = peak_signal_noise_ratio(ground_truth_image, output_image[0, :, :, 0])\n","\n","    # calculate MSE (Mean Squared Error)\n","    mse_value = mean_squared_error(ground_truth_image, output_image[0, :, :, 0])\n","\n","    # calculate SSIM (Structural Similarity Index)\n","    ssim_value = structural_similarity(ground_truth_image, output_image[0, :, :, 0], data_range=1.0)\n","\n","    # # Print metrics values\n","    # print(f\"Metrics for {random_image_filename}:\")\n","    # print(f\"PSNR: {psnr_value}\")\n","    # print(f\"MSE: {mse_value}\")\n","    # print(f\"SSIM: {ssim_value}\\n\")\n","\n","    psnr_scores.append(psnr_value)\n","    mse_scores.append(mse_value)\n","    ssim_scores.append(ssim_value)\n","\n","# Plot PSNR, MSE, and SSIM scores\n","plt.figure(figsize=(10, 6))\n","\n","plt.subplot(3, 1, 1)\n","plt.plot(psnr_scores, marker='o')\n","plt.title('PSNR Scores')\n","plt.xlabel('Image Index')\n","plt.ylabel('PSNR')\n","\n","plt.subplot(3, 1, 2)\n","plt.plot(mse_scores, marker='o')\n","plt.title('MSE Scores')\n","plt.xlabel('Image Index')\n","plt.ylabel('MSE')\n","\n","plt.subplot(3, 1, 3)\n","plt.plot(ssim_scores, marker='o')\n","plt.title('SSIM Scores')\n","plt.xlabel('Image Index')\n","plt.ylabel('SSIM')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e0c6503b-758a-4fef-813d-a98c76bf1de7","metadata":{"id":"e0c6503b-758a-4fef-813d-a98c76bf1de7"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# assuming psnr_scores, mse_scores, and ssim_scores are lists of scores\n","# calculate histogram for PSNR scores\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 3, 1)\n","plt.hist(psnr_scores, bins=20, color='blue', alpha=0.7)\n","plt.title('PSNR Distribution')\n","plt.xlabel('PSNR Score')\n","plt.ylabel('Frequency')\n","\n","# calculate histogram for MSE scores\n","plt.subplot(1, 3, 2)\n","plt.hist(mse_scores, bins=20, color='pink', alpha=0.7)\n","plt.title('MSE Distribution')\n","plt.xlabel('MSE Score')\n","plt.ylabel('Frequency')\n","\n","# calculate histogram for SSIM scores\n","plt.subplot(1, 3, 3)\n","plt.hist(ssim_scores, bins=20, color='purple', alpha=0.7)\n","plt.title('SSIM Distribution')\n","plt.xlabel('SSIM Score')\n","plt.ylabel('Frequency')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# calculate percentages of values within certain ranges for each metric\n","def calculate_percentage(scores, range_start, range_end):\n","    values_within_range = [score for score in scores if range_start <= score <= range_end]\n","    percentage = (len(values_within_range) / len(scores)) * 100\n","    return percentage\n","\n","# define range for each metric\n","psnr_range = (30, 40)\n","mse_range = (0, 0.05)\n","ssim_range = (0.95, 1)\n","\n","# calculate percentages for each range\n","psnr_percentage = calculate_percentage(psnr_scores, psnr_range[0], psnr_range[1])\n","mse_percentage = calculate_percentage(mse_scores, mse_range[0], mse_range[1])\n","ssim_percentage = calculate_percentage(ssim_scores, ssim_range[0], ssim_range[1])\n","\n","print(f'Percentage of PSNR scores in range {psnr_range}: {psnr_percentage}%')\n","print(f'Percentage of MSE scores in range {mse_range}: {mse_percentage}%')\n","print(f'Percentage of SSIM scores in range {ssim_range}: {ssim_percentage}%')\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3.10.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"a30072751ebdd9e38b3a3723274826dbc6c580cc83e8305b93d67478e6165946"}}},"nbformat":4,"nbformat_minor":5}
