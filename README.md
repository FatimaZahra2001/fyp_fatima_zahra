### Author: Fatima Zahra Al Hajji
### student ID: 2188877
### Date: 08.04.2024

### This file will help you understand how my code is split and how they all link together.

The files are split into 3 directories:
    -> Data Curation
    -> Machine_Learning_Models
    -> Sinogram_Processing
and each of these contain Jupyter notebooks (.ipynb) or Python files (.py) for the tasks I carried out for my FYP.

    -> Data Curation:
        -> ML
            -> data_augmentation.ipynb : contains a script that preprocesses my image reconstructions generated by NIRFAST
        -> NIRFAST
            -> node_generation.ipynb : this is a helper script to help automate the files data (.link, .source, .meas) generation in NIRFAST

    -> Machine_Learning_Models:

        -> hyperparameter_tuning
            -> noise_tuning.ipynb : notebook to tune my models for noise data
            -> regularisation_tuning_unet.py : python script to tune my regularised unets
            -> unet_hyperparameter_tuning.ipynb : notebook to tune models for perfect data

        -> image reconstruction:
            -> noise_image_reconstructions_unet.ipynb : unet for noise image reconstruction datasets
            -> perfect_image_reconstructions_unet.ipynb : unet for perfect image reconstruction datasets

        -> sinogram:
            -> sinogram_predictions_unet.ipynb : notebook containing both unets for noise and perfect data

    -> Sinogram_Processing:

        -> sinogram.ipynb : script to generate sinograms from image reconstructions generated by NIRFAST
        -> to_image_reconstruction.ipynb : script to generate image reconstructions from predicted sinograms from unet models



